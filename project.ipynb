{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP467 Assignment 1\n",
    "\n",
    "The input images are put in the Images folder. Output images are saved in the Results folder and seperated by the questions (i.e. the output images of questions 1 are saved in Results/Question 1 and output images for question 2 are saved in Results/Question 2, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the lena image so that it can be resized and interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image = cv2.imread('Images/lena.tif')\n",
    "\n",
    "# Get original dimensions\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Calculate new dimensions (1/2 of the original in each dimension)\n",
    "down_width = width // 2\n",
    "down_height = height // 2\n",
    "\n",
    "# Resize the image\n",
    "downscaled_image = cv2.resize(image, (down_width, down_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest neighbor interpolation implementation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create an empty matrix for the rescaled image (original dimensions)\n",
    "rescaled_image_np = np.zeros((height, width, 3), dtype=downscaled_image.dtype)\n",
    "\n",
    "# Nearest-neighbor interpolation\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        # Find the nearest pixel in the downscaled image\n",
    "        nearest_i = int(i / 2)\n",
    "        nearest_j = int(j / 2)\n",
    "\n",
    "        # Assign the nearest pixel value to the rescaled image\n",
    "        rescaled_image_np[i, j] = downscaled_image[nearest_i, nearest_j]\n",
    "\n",
    "# Save the rescaled image using OpenCV\n",
    "cv2.imwrite('Results/Question 1/lena_nearest_scratch.tif', rescaled_image_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest neighbor interpolation using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upscaled_image_cv = cv2.resize(downscaled_image, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Save the upscaled image using OpenCV\n",
    "cv2.imwrite('Results/Question 1/lena_nearest_cv.tif', upscaled_image_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilinear Interpolation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downscaled_array = np.array(downscaled_image)\n",
    "\n",
    "# Initialize an empty array for the upscaled image\n",
    "rescaled_image_np = np.zeros((height, width, 3), dtype=downscaled_image.dtype)\n",
    "\n",
    "# Calculate scaling factors\n",
    "scale_x = down_width / width\n",
    "scale_y = down_height / height\n",
    "\n",
    "# Perform bilinear interpolation\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        # Corresponding position in the downscaled image\n",
    "        x = j * scale_x\n",
    "        y = i * scale_y\n",
    "\n",
    "        # Coordinates of the top-left pixel\n",
    "        x0 = int(np.floor(x))\n",
    "        y0 = int(np.floor(y))\n",
    "\n",
    "        # Coordinates of the bottom-right pixel\n",
    "        x1 = min(x0 + 1, down_width - 1)\n",
    "        y1 = min(y0 + 1, down_height - 1)\n",
    "\n",
    "        # Calculate the distance between the target position and the neighboring pixels\n",
    "        dx = x - x0\n",
    "        dy = y - y0\n",
    "\n",
    "        # Retrieve pixel values\n",
    "        Ia = downscaled_array[y0, x0]\n",
    "        Ib = downscaled_array[y1, x0]\n",
    "        Ic = downscaled_array[y0, x1]\n",
    "        Id = downscaled_array[y1, x1]\n",
    "\n",
    "        # Compute interpolated value\n",
    "\n",
    "        # Get weighted average contribution for each neighbour\n",
    "        top_left_pixel = (1 - dx) * (1 - dy) * Ia\n",
    "        top_right_pixel = dx * (1 - dy) * Ic\n",
    "        bottom_left_pixel = (1 - dx) * dy * Ib\n",
    "        bottom_right_pixel = dx * dy * Id\n",
    "\n",
    "        # Calculate weighted average\n",
    "        weighted_average = top_left_pixel + top_right_pixel + bottom_left_pixel + bottom_right_pixel\n",
    "    \n",
    "        rescaled_image_np[i, j] = np.clip(weighted_average, 0, 255)\n",
    "\n",
    "cv2.imwrite('Results/Question 1/lena_bilinear_scratch.tif', rescaled_image_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilinear Interpolation using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upscaled_image_cv = cv2.resize(downscaled_image, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# Save the upscaled image using OpenCV\n",
    "cv2.imwrite('Results/Question 1/lena_bilinear_cv.tif', upscaled_image_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bicubic Interpolation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_kernel(x, a=-0.5):\n",
    "    \"\"\"\n",
    "    Cubic kernel function for bicubic interpolation.\n",
    "    \n",
    "    Parameters:\n",
    "        x (float): The distance from the central pixel.\n",
    "        a (float): Parameter for the cubic function. Commonly -0.5 (Catmull-Rom).\n",
    "        \n",
    "    Returns:\n",
    "        float: Weight for the given distance.\n",
    "    \"\"\"\n",
    "    abs_x = np.abs(x)\n",
    "    if abs_x <= 1:\n",
    "        return (a + 2) * abs_x**3 - (a + 3) * abs_x**2 + 1\n",
    "    elif 1 < abs_x < 2:\n",
    "        return a * abs_x**3 - 5*a * abs_x**2 + 8*a * abs_x - 4*a\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bicubic_interpolate(image, scale):\n",
    "    \"\"\"\n",
    "    Rescales the image using bicubic interpolation.\n",
    "    \n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image as a NumPy array.\n",
    "        scale (float): Scaling factor (e.g., 2 for doubling the size).\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Upscaled image.\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 2:  # Grayscale\n",
    "        channels = 1\n",
    "    else:\n",
    "        channels = image.shape[2]\n",
    "    \n",
    "    in_height, in_width = image.shape[:2]\n",
    "    out_height, out_width = int(in_height * scale), int(in_width * scale)\n",
    "    \n",
    "    # Prepare the output image\n",
    "    if channels == 1:\n",
    "        output = np.zeros((out_height, out_width), dtype=image.dtype)\n",
    "    else:\n",
    "        output = np.zeros((out_height, out_width, channels), dtype=image.dtype)\n",
    "    \n",
    "    # Precompute the scaled coordinates\n",
    "    scale_inv = 1 / scale\n",
    "    for y in range(out_height):\n",
    "        for x in range(out_width):\n",
    "            # Map the coordinates back to the input image\n",
    "            src_x = x * scale_inv\n",
    "            src_y = y * scale_inv\n",
    "            \n",
    "            x_int = int(np.floor(src_x))\n",
    "            y_int = int(np.floor(src_y))\n",
    "            \n",
    "            x_frac = src_x - x_int\n",
    "            y_frac = src_y - y_int\n",
    "            \n",
    "            # Accumulate the results\n",
    "            for m in range(-1, 3):\n",
    "                for n in range(-1, 3):\n",
    "                    # Neighbor coordinates\n",
    "                    neighbor_x = x_int + n\n",
    "                    neighbor_y = y_int + m\n",
    "                    \n",
    "                    # Handle boundary conditions\n",
    "                    neighbor_x = min(max(neighbor_x, 0), in_width - 1)\n",
    "                    neighbor_y = min(max(neighbor_y, 0), in_height - 1)\n",
    "                    \n",
    "                    weight = cubic_kernel(m - y_frac) * cubic_kernel(n - x_frac)\n",
    "                    \n",
    "                    if channels == 1:\n",
    "                        output[y, x] += image[neighbor_y, neighbor_x] * weight\n",
    "                    else:\n",
    "                        output[y, x, :] += image[neighbor_y, neighbor_x, :] * weight\n",
    "    \n",
    "    # Clip the values to valid range\n",
    "    output = np.clip(output, 0, 255)\n",
    "    output = output.astype(image.dtype)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscaled_image = np.array(downscaled_image).astype(np.float32)\n",
    "    \n",
    "# Check if the image has an alpha channel and remove it if present\n",
    "if downscaled_image.ndim == 3 and downscaled_image.shape[2] == 4:\n",
    "    downscaled_image = downscaled_image[:, :, :3]\n",
    "\n",
    "# Define the scaling factor (2x in each dimension)\n",
    "scale_factor = 2.0\n",
    "\n",
    "# Perform bicubic interpolation\n",
    "image = bicubic_interpolate(downscaled_image, scale_factor)\n",
    "upscaled_image = Image.fromarray(image.astype(np.uint8))\n",
    "upscaled_image.save('Results/Question 1/lena_bicubic_scratch.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bicubic Interpolation using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenCV's resize function with INTER_CUBIC for bicubic interpolation\n",
    "upscaled_image_cv = cv2.resize(downscaled_image_cv, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "bicubic_cv_image = Image.fromarray(cv2.cvtColor(upscaled_image_cv, cv2.COLOR_BGR2RGB))\n",
    "bicubic_cv_image.save('Results/Question 1/lena_bicubic_cv.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantitively compare images (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(image1_path, image2_path):\n",
    "    \"\"\"\n",
    "    Computes the Mean Squared Error between two images.\n",
    "\n",
    "    Parameters:\n",
    "        image1_path (str): Path to the first image (original image).\n",
    "        image2_path (str): Path to the second image (interpolated image).\n",
    "\n",
    "    Returns:\n",
    "        float: The MSE between the two images.\n",
    "    \"\"\"\n",
    "    img1 = Image.open(image1_path).convert('RGB')\n",
    "    img2 = Image.open(image2_path).convert('RGB')\n",
    "\n",
    "    img1_np = np.array(img1, dtype=np.float64)\n",
    "    img2_np = np.array(img2, dtype=np.float64)\n",
    "\n",
    "    # Ensure the images have the same dimensions\n",
    "    if img1_np.shape != img2_np.shape:\n",
    "        raise ValueError(f\"Image dimensions do not match: {img1_np.shape} vs {img2_np.shape}\")\n",
    "\n",
    "    # Compute the Mean Squared Error\n",
    "    mse = np.mean((img1_np - img2_np) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error between Original and Interpolated Images:\n",
      "Nearest Neighbor (Scratch): MSE = 118.98\n",
      "Nearest Neighbor (OpenCV): MSE = 118.98\n",
      "Bilinear (Scratch): MSE = 143.44\n",
      "Bilinear (OpenCV): MSE = 93.95\n",
      "Bicubic (Scratch): MSE = 139.06\n",
      "Bicubic (OpenCV): MSE = 74.55\n"
     ]
    }
   ],
   "source": [
    "resultsPath = 'Results/Question 1/'\n",
    "original_image_path = 'Images/lena.tif'\n",
    "\n",
    "interpolated_images = {\n",
    "    'Nearest Neighbor (Scratch)': f'{resultsPath}lena_nearest_scratch.tif',\n",
    "    'Nearest Neighbor (OpenCV)': f'{resultsPath}lena_nearest_cv.tif',\n",
    "    'Bilinear (Scratch)': f'{resultsPath}lena_bilinear_scratch.tif',\n",
    "    'Bilinear (OpenCV)': f'{resultsPath}lena_bilinear_cv.tif',\n",
    "    'Bicubic (Scratch)': f'{resultsPath}lena_bicubic_scratch.tif',\n",
    "    'Bicubic (OpenCV)': f'{resultsPath}lena_bicubic_cv.tif'\n",
    "}\n",
    "\n",
    "# Compute and print the MSE for each interpolated image\n",
    "print(\"Mean Squared Error between Original and Interpolated Images:\")\n",
    "for method, image_path in interpolated_images.items():\n",
    "    try:\n",
    "        mse = compute_mse(original_image_path, image_path)\n",
    "        print(f\"{method}: MSE = {mse:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{method}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Negative Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Images/cameraman.tif'\n",
    "img = Image.open(image_path).convert('L')\n",
    "img_np = np.array(img)\n",
    "\n",
    "# Negative of the Image\n",
    "def negative_image(image_np):\n",
    "    return 255 - image_np\n",
    "\n",
    "# Save the negative image\n",
    "resultsPath = 'Results/Question 2/'\n",
    "cameraman_negative = negative_image(img_np)\n",
    "Image.fromarray(cameraman_negative).save(f'{resultsPath}cameraman_negative.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power-Law Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power-Law Transformation (Gamma Correction)\n",
    "def power_law_transformation(image_np, gamma, c=1):\n",
    "    # Normalize the image to the range [0, 1]\n",
    "    normalized_img = image_np / 255.0\n",
    "\n",
    "    # Apply the power-law transformation\n",
    "    transformed_img = c * np.power(normalized_img, gamma)\n",
    "\n",
    "    # Scale back to [0, 255] and cast to uint8\n",
    "    return np.uint8(transformed_img * 255)\n",
    "\n",
    "gamma_value = 1.5\n",
    "cameraman_power = power_law_transformation(img_np, gamma_value)\n",
    "Image.fromarray(cameraman_power).save(f'{resultsPath}cameraman_power.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bit-Plane Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bit-Plane Slicing\n",
    "def bit_plane_slicing(image_np, bit):\n",
    "    # Shift the bits and apply bitwise AND with 1 to extract the bit-plane\n",
    "    return (image_np >> bit) & 1\n",
    "\n",
    "# Save bit-plane images\n",
    "for i in range(8):\n",
    "    bit_plane_image = bit_plane_slicing(img_np, i) * 255  # Scale to [0, 255]\n",
    "    Image.fromarray(np.uint8(bit_plane_image)).save(f'{resultsPath}cameraman_b{i+1}.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Images/einstein.tif'\n",
    "img = Image.open(image_path).convert('L')\n",
    "img_np = np.array(img)\n",
    "\n",
    "# Compute the histogram\n",
    "hist, bins = np.histogram(img_np.flatten(), bins=256, range=[0,256])\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * 255 / cdf[-1]  # Scale to [0,255]\n",
    "\n",
    "# Use linear interpolation of the CDF to find new pixel values\n",
    "img_equalized_np = np.interp(img_np.flatten(), bins[:-1], cdf_normalized)\n",
    "\n",
    "# Reshape the flattened array back to the original image shape\n",
    "img_equalized_np = img_equalized_np.reshape(img_np.shape).astype('uint8')\n",
    "\n",
    "img_equalized = Image.fromarray(img_equalized_np)\n",
    "img_equalized.save('Results/Question 3/einstein_equalized.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_matching(source, template):\n",
    "    \"\"\"\n",
    "    Adjust the pixel values of a grayscale image such that its histogram\n",
    "    matches that of a target image.\n",
    "\n",
    "    Parameters:\n",
    "    - source: NumPy array of the source image\n",
    "    - template: NumPy array of the template image (reference)\n",
    "\n",
    "    Returns:\n",
    "    - matched: NumPy array of the transformed output image\n",
    "    \"\"\"\n",
    "    # Flatten the images\n",
    "    source_flat = source.ravel()\n",
    "    template_flat = template.ravel()\n",
    "\n",
    "    # Get the set of unique pixel values and their corresponding indices and counts\n",
    "    _, bin_idx, s_counts = np.unique(source_flat, return_inverse=True, return_counts=True)\n",
    "    t_values, t_counts = np.unique(template_flat, return_counts=True)\n",
    "\n",
    "    # Compute the normalized CDFs\n",
    "    s_quantiles = np.cumsum(s_counts).astype(np.float64) / source_flat.size\n",
    "    t_quantiles = np.cumsum(t_counts).astype(np.float64) / template_flat.size\n",
    "\n",
    "    # Create interpolation function (inverse CDF of the template)\n",
    "    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n",
    "\n",
    "    # Map the pixel values of the source image to the template\n",
    "    matched = interp_t_values[bin_idx].reshape(source.shape).astype('uint8')\n",
    "\n",
    "    return matched\n",
    "\n",
    "# Load the source images\n",
    "source_image_path = 'Images/chest_x-ray1.jpeg'\n",
    "template_image_path = 'Images/chest_x-ray2.jpeg'\n",
    "\n",
    "source_img = Image.open(source_image_path).convert('L')\n",
    "template_img = Image.open(template_image_path).convert('L')\n",
    "\n",
    "source_np = np.array(source_img)\n",
    "template_np = np.array(template_img)\n",
    "\n",
    "# Apply histogram matching\n",
    "matched_np = histogram_matching(source_np, template_np)\n",
    "\n",
    "# Save the output image\n",
    "matched_img = Image.fromarray(matched_np)\n",
    "matched_img.save('Results/Question 3/chest_x-ray3.jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
